{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "/home/project_amadeus/home/hbdat/[RELEASE]_DenseAttentionZSL\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os,sys\n",
    "pwd = os.getcwd()\n",
    "parent = '/'.join(pwd.split('/')[:-1])\n",
    "sys.path.insert(0,parent)\n",
    "os.chdir(parent)\n",
    "#%%\n",
    "print('-'*30)\n",
    "print(os.getcwd())\n",
    "print('-'*30)\n",
    "#%%\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from core.DAZLE import DAZLE\n",
    "from core.CUBDataLoader_standard_split import CUBDataLoader\n",
    "from core.helper_func import eval_zs_gzsl,visualize_attention,eval_zs_gzsl#,get_attribute_attention_stats\n",
    "from global_setting import NFS_path\n",
    "#from core.Scheduler import Scheduler\n",
    "import importlib\n",
    "import pdb\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_GPU = 0\n",
    "device = torch.device(\"cuda:{}\".format(idx_GPU) if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!! Standard Split !!!!!!!!!!\n",
      "/home/project_amadeus/mnt/raptor/hbdat/Attention_over_attention/\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "CUB\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "_____\n",
      "/home/project_amadeus/mnt/raptor/hbdat/Attention_over_attention/data/CUB/feature_map_ResNet_101_CUB.hdf5\n",
      "Expert Attr\n",
      "Finish loading data in  61.513001\n"
     ]
    }
   ],
   "source": [
    "dataloader = CUBDataLoader(NFS_path,device,is_unsupervised_attr=False,is_balance=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attr_entropy(att):  #the lower the more discriminative it is\n",
    "    eps = 1e-8\n",
    "    mass=np.sum(att,axis = 0,keepdims=True)\n",
    "    att_n = np.divide(att,mass+eps)\n",
    "    entropy = np.sum(-att_n*np.log(att_n+eps),axis=0)\n",
    "    assert len(entropy.shape)==1\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "nepoches = 1\n",
    "niters = dataloader.ntrain * nepoches//batch_size\n",
    "dim_f = 2048\n",
    "dim_v = 300\n",
    "init_w2v_att = dataloader.w2v_att\n",
    "att = dataloader.att#dataloader.normalize_att#\n",
    "normalize_att = dataloader.att\n",
    "#%% attribute selection\n",
    "attr_entropy = get_attr_entropy(att.cpu().numpy())\n",
    "idx_attr_dis = np.argsort(attr_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([312, 300])\n"
     ]
    }
   ],
   "source": [
    "print(init_w2v_att.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    lr = []\n",
    "    for param_group in optimizer.param_groups:\n",
    "        lr.append(param_group['lr'])\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 214#215#\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "batch_size = 50\n",
    "nepoches = 20\n",
    "niters = dataloader.ntrain * nepoches//batch_size\n",
    "dim_f = 2048\n",
    "dim_v = 300\n",
    "init_w2v_att = dataloader.w2v_att\n",
    "att = dataloader.att#dataloader.normalize_att#\n",
    "normalize_att = dataloader.normalize_att\n",
    "#assert (att.min().item() == 0 and att.max().item() == 1)\n",
    "\n",
    "trainable_w2v = True\n",
    "lambda_ = 0.1\n",
    "bias = 0\n",
    "prob_prune = 0\n",
    "uniform_att_1 = False\n",
    "uniform_att_2 = False\n",
    "\n",
    "seenclass = dataloader.seenclasses\n",
    "unseenclass = dataloader.unseenclasses\n",
    "desired_mass = 1#unseenclass.size(0)/(seenclass.size(0)+unseenclass.size(0))\n",
    "report_interval = niters//nepoches#10000//batch_size#\n",
    "\n",
    "model = DAZLE(dim_f,dim_v,init_w2v_att,att,normalize_att,\n",
    "            seenclass,unseenclass,\n",
    "            lambda_,\n",
    "            trainable_w2v,normalize_V=False,normalize_F=True,is_conservative=True,\n",
    "            uniform_att_1=uniform_att_1,uniform_att_2=uniform_att_2,\n",
    "            prob_prune=prob_prune,desired_mass=desired_mass, is_conv=False,\n",
    "            is_bias=True)\n",
    "model.to(device)\n",
    "\n",
    "setup = {'pmp':{'init_lambda':0.1,'final_lambda':0.1,'phase':0.8},\n",
    "         'desired_mass':{'init_lambda':-1,'final_lambda':-1,'phase':0.8}}\n",
    "print(setup)\n",
    "#scheduler = Scheduler(model,niters,batch_size,report_interval,setup)\n",
    "\n",
    "params_to_update = []\n",
    "params_names = []\n",
    "for name,param in model.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        params_names.append(name)\n",
    "        print(\"\\t\",name)\n",
    "#%%\n",
    "lr = 0.0001\n",
    "weight_decay = 0.00005#0.000#0.#\n",
    "momentum = 0.9#0.#\n",
    "#%%\n",
    "lr_seperator = 1\n",
    "lr_factor = 1\n",
    "print('default lr {} {}x lr {}'.format(params_names[:lr_seperator],lr_factor,params_names[lr_seperator:]))\n",
    "optimizer  = optim.RMSprop( params_to_update ,lr=lr,weight_decay=weight_decay, momentum=momentum)\n",
    "print('-'*30)\n",
    "print('learing rate {}'.format(lr))\n",
    "print('trainable V {}'.format(trainable_w2v))\n",
    "print('lambda_ {}'.format(lambda_))\n",
    "print('optimized seen only')\n",
    "print('optimizer: RMSProp with momentum = {} and weight_decay = {}'.format(momentum,weight_decay))\n",
    "print('-'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 0, 'loss': 5.307318687438965, 'loss_CE': 5.271770000457764, 'loss_cal': 0.35548919439315796, 'acc_seen': nan, 'acc_novel': 0.040221136063337326, 'H': 0, 'acc_zs': 0.04022114351391792}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 177, 'loss': 1.6891649961471558, 'loss_CE': 1.5842840671539307, 'loss_cal': 1.0488090515136719, 'acc_seen': nan, 'acc_novel': 0.4655452370643616, 'H': 0, 'acc_zs': 0.5405555367469788}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 354, 'loss': 1.5217909812927246, 'loss_CE': 1.4060150384902954, 'loss_cal': 1.1577597856521606, 'acc_seen': nan, 'acc_novel': 0.510532796382904, 'H': 0, 'acc_zs': 0.6040189266204834}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 531, 'loss': 1.156381607055664, 'loss_CE': 1.0383371114730835, 'loss_cal': 1.1804451942443848, 'acc_seen': nan, 'acc_novel': 0.5140025019645691, 'H': 0, 'acc_zs': 0.6206724643707275}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 708, 'loss': 1.1116386651992798, 'loss_CE': 0.9800852537155151, 'loss_cal': 1.3155337572097778, 'acc_seen': nan, 'acc_novel': 0.5589466094970703, 'H': 0, 'acc_zs': 0.6678099632263184}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 885, 'loss': 1.3317115306854248, 'loss_CE': 1.1996527910232544, 'loss_cal': 1.320586919784546, 'acc_seen': nan, 'acc_novel': 0.5589466094970703, 'H': 0, 'acc_zs': 0.6678099632263184}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 1062, 'loss': 1.118662714958191, 'loss_CE': 0.9750721454620361, 'loss_cal': 1.4359060525894165, 'acc_seen': nan, 'acc_novel': 0.5580828785896301, 'H': 0, 'acc_zs': 0.6697779297828674}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 1239, 'loss': 0.8553117513656616, 'loss_CE': 0.6984010338783264, 'loss_cal': 1.5691068172454834, 'acc_seen': nan, 'acc_novel': 0.5738272070884705, 'H': 0, 'acc_zs': 0.6717338562011719}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 1416, 'loss': 0.6992800831794739, 'loss_CE': 0.5499823689460754, 'loss_cal': 1.4929770231246948, 'acc_seen': nan, 'acc_novel': 0.5738272070884705, 'H': 0, 'acc_zs': 0.6717338562011719}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 1593, 'loss': 1.0170717239379883, 'loss_CE': 0.88196861743927, 'loss_cal': 1.3510308265686035, 'acc_seen': nan, 'acc_novel': 0.5738272070884705, 'H': 0, 'acc_zs': 0.6717338562011719}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 1770, 'loss': 0.9129882454872131, 'loss_CE': 0.7532180547714233, 'loss_cal': 1.5977017879486084, 'acc_seen': nan, 'acc_novel': 0.5701281428337097, 'H': 0, 'acc_zs': 0.6731362342834473}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 1947, 'loss': 0.6349995136260986, 'loss_CE': 0.48872146010398865, 'loss_cal': 1.4627807140350342, 'acc_seen': nan, 'acc_novel': 0.5772320032119751, 'H': 0, 'acc_zs': 0.6761006116867065}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 2124, 'loss': 0.7970255613327026, 'loss_CE': 0.6616990566253662, 'loss_cal': 1.3532648086547852, 'acc_seen': nan, 'acc_novel': 0.5840730667114258, 'H': 0, 'acc_zs': 0.6778362989425659}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 2301, 'loss': 0.7347122430801392, 'loss_CE': 0.5974063873291016, 'loss_cal': 1.373058557510376, 'acc_seen': nan, 'acc_novel': 0.5840730667114258, 'H': 0, 'acc_zs': 0.6778362989425659}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 2478, 'loss': 0.5548276901245117, 'loss_CE': 0.3850424587726593, 'loss_cal': 1.6978520154953003, 'acc_seen': nan, 'acc_novel': 0.5840730667114258, 'H': 0, 'acc_zs': 0.6778362989425659}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 2655, 'loss': 0.6615085601806641, 'loss_CE': 0.5202628374099731, 'loss_cal': 1.4124568700790405, 'acc_seen': nan, 'acc_novel': 0.5840730667114258, 'H': 0, 'acc_zs': 0.6778362989425659}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 2832, 'loss': 0.6729946136474609, 'loss_CE': 0.501806914806366, 'loss_cal': 1.711876630783081, 'acc_seen': nan, 'acc_novel': 0.5840730667114258, 'H': 0, 'acc_zs': 0.6778362989425659}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 3009, 'loss': 0.6648485064506531, 'loss_CE': 0.5202063322067261, 'loss_cal': 1.4464218616485596, 'acc_seen': nan, 'acc_novel': 0.5840730667114258, 'H': 0, 'acc_zs': 0.6778362989425659}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 3186, 'loss': 0.5674977898597717, 'loss_CE': 0.42501401901245117, 'loss_cal': 1.424837589263916, 'acc_seen': nan, 'acc_novel': 0.5840730667114258, 'H': 0, 'acc_zs': 0.6778362989425659}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 3363, 'loss': 0.5623935461044312, 'loss_CE': 0.4077602028846741, 'loss_cal': 1.5463331937789917, 'acc_seen': nan, 'acc_novel': 0.5840730667114258, 'H': 0, 'acc_zs': 0.6778362989425659}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 3540, 'loss': 0.6784080862998962, 'loss_CE': 0.5070964694023132, 'loss_cal': 1.713115930557251, 'acc_seen': nan, 'acc_novel': 0.5840730667114258, 'H': 0, 'acc_zs': 0.6778362989425659}\n"
     ]
    }
   ],
   "source": [
    "best_performance = [0,0,0,0]\n",
    "for i in range(0,niters):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    batch_label, batch_feature, batch_att = dataloader.next_batch(batch_size)\n",
    "    out_package = model(batch_feature)\n",
    "    \n",
    "    in_package = out_package\n",
    "    in_package['batch_label'] = batch_label\n",
    "    \n",
    "    out_package=model.compute_loss(in_package)\n",
    "    loss,loss_CE,loss_cal = out_package['loss'],out_package['loss_CE'],out_package['loss_cal']\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i%report_interval==0:\n",
    "        print('-'*30)\n",
    "        acc_seen, acc_novel, H, acc_zs = eval_zs_gzsl(dataloader,model,device,bias_seen=-bias,bias_unseen=bias)\n",
    "        \n",
    "        if acc_zs > best_performance[3]:\n",
    "            best_performance = [acc_seen, acc_novel, H, acc_zs]\n",
    "        stats_package = {'iter':i, 'loss':loss.item(), 'loss_CE':loss_CE.item(),\n",
    "                         'loss_cal': loss_cal.item(),\n",
    "                         'acc_seen':best_performance[0], 'acc_novel':best_performance[1], 'H':best_performance[2], 'acc_zs':best_performance[3]}\n",
    "        \n",
    "        print(stats_package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
